<!DOCTYPE html>
<html lang="pt">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    <title>Projeto - Pipeline Uber NYC</title>
    <link rel="icon" type="image/x-icon" href="assets/favicon.ico" />
    <!-- Google Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link href="https://fonts.googleapis.com/css2?family=Plus+Jakarta+Sans:wght@100;200;300;400;500;600;700;800;900&display=swap" rel="stylesheet" />
    <!-- Bootstrap Icons -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.8.1/font/bootstrap-icons.css" rel="stylesheet" />
    <!-- Core theme CSS -->
    <link href="css/styles.css" rel="stylesheet" />
</head>
<body class="d-flex flex-column h-100 bg-light">

<main class="flex-shrink-0">
    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-light bg-white py-3">
        <div class="container px-5">
            <a class="navbar-brand" href="index.html"><span class="fw-bolder text-primary">Alcides G. Portfólio</span></a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav ms-auto mb-2 mb-lg-0 small fw-bolder">
                    <li class="nav-item"><a class="nav-link" href="index.html">Home</a></li>
                    <li class="nav-item"><a class="nav-link" href="resume.html">Currículo</a></li>
                    <li class="nav-item"><a class="nav-link" href="projects.html">Projetos</a></li>
                    <li class="nav-item"><a class="nav-link" href="contact.html">Contato</a></li>
                </ul>
            </div>
        </div>
    </nav>

    <!-- Título -->
    <div class="container px-5 my-5">
        <div class="text-center mb-5">
            <h1 class="display-5 fw-bolder mb-0"><span class="text-gradient d-inline">Pipeline Uber NYC</span></h1>
        </div>

        <!-- Projeto -->
        <div class="row gx-5 justify-content-center">
            <div class="col-lg-11 col-xl-9 col-xxl-8">
                <section>
                    <div class="card shadow border-0 rounded-4 mb-5">
                        <div class="card-body p-5">
                            <div class="row gx-5">
                                <div class="col-12">
                                    <p>Esse projeto foi pensado para mostrar, na prática, como construir uma pipeline de dados completa, do zero até a entrega em data warehouses prontos para análise. O ponto de partida foi um dataset público do <strong>Kaggle</strong>, uma plataforma bastante conhecida por hospedar dados e competições de ciência de dados. O conjunto escolhido foi o <strong>"Uber Pickups in New York City"</strong>, que contém registros de corridas da Uber em Nova York, com informações como data, hora, latitude, longitude, entre outros.</p>

                                    <p>Apesar do volume de dados e da riqueza de informações, os arquivos disponibilizados tinham várias tabelas — e nem todas com colunas úteis para este projeto. O foco foi nas tabelas que possuíam dados de <strong>localização geográfica (latitude e longitude)</strong>, porque a ideia era cruzar essas coordenadas com dados de regiões dos EUA (cidade, estado, condado, etc.).</p>

                                    <p>Para fazer esse enriquecimento geográfico, utilizei os <strong>shapefiles oficiais do Censo Americano (Census Bureau)</strong>, disponíveis publicamente em <a href="https://www2.census.gov/geo/tiger/TIGER2023/COUNTY/tl_2023_us_county.zip" target="_blank">tl_2023_us_county.zip</a>. Com isso, foi possível mapear cada ponto da Uber para dentro de uma região geográfica mais legível, permitindo análises mais direcionadas.</p>
                                    <div class="d-flex align-items-center justify-content-between mb-4">
                                        <h5 class="text-primary fw-bolder mb-0">Objetivo do Projeto</h5>
                                    </div>
                                    <!-- <h5 class="fw-bold mt-4">Objetivo do Projeto</h5> -->
                                    <p>O principal objetivo foi <strong>criar uma estrutura de data warehouses separados por tipo de transporte</strong> (quando identificado), com dados já tratados, enriquecidos e prontos para análises de negócios, visualizações ou aplicações analíticas.</p>
                                    <div class="d-flex align-items-center justify-content-between mb-4">
                                        <h5 class="text-primary fw-bolder mb-0">Stack e Ferramentas Utilizadas</h5>
                                    </div>
                                    <!-- <h5 class="fw-bold mt-4">Stack e Ferramentas Utilizadas</h5> -->
                                    <ul>
                                        <li><strong>Apache Spark:</strong> para processar os dados, fazer as transformações e os cruzamentos geográficos.</li>
                                        <li><strong>MinIO:</strong> utilizado como armazenamento de objetos, simulando um bucket S3.</li>
                                        <li><strong>PostgreSQL:</strong> banco de dados relacional para armazenamento final dos data warehouses.</li>
                                        <li><strong>Docker + Docker Compose:</strong> para subir todos os serviços em containers locais.</li>
                                    </ul>

                                    <p>Ainda que o uso de Docker esteja mais associado à infraestrutura, acredito que dominar esse tipo de ferramenta dá ao engenheiro de dados mais agilidade e independência no dia a dia.</p>
                                    <div class="d-flex align-items-center justify-content-between mb-4">
                                        <h5 class="text-primary fw-bolder mb-0">Arquitetura da Pipeline - Modelo em Camadas (Medalhão)</h5>
                                    </div>

                                    <p>
                                        Quando pensamos em construir pipelines de dados, uma das arquiteturas mais conhecidas é o <strong>modelo em camadas, também chamado de Medalhão</strong>. 
                                        A ideia é dividir o fluxo em estágios bem definidos — <strong>Raw, Bronze, Silver e Gold</strong> — de modo que cada camada tenha um propósito claro: 
                                        desde o armazenamento dos dados brutos até a entrega final, já pronta para análise.
                                    </p>

                                    <p>
                                        Para tornar o processo mais didático, cada camada conta com um fluxograma em vídeo (feito no Draw.io), exibido abaixo em loop, ilustrando de forma visual o que acontece em cada etapa.
                                    </p>

                                    <!-- Camada RAW -->
                                    <h6 class="fw-bold mt-4 text-secondary">Camada Raw</h6>
                                    <p>
                                        O objetivo da camada Raw é simples: <strong>extrair os dados da fonte e salvá-los em seu formato original no MinIO</strong>.  
                                        Foram desenvolvidos dois notebooks:
                                    </p>
                                    <ul>
                                        <li><code>extract_geospatial_data_from_census.ipynb</code>: baixa shapefiles oficiais do Censo Americano diretamente do site do Census Bureau.</li>
                                        <li><code>extract_uber_data_from_kaggle.ipynb</code>: conecta-se à API do Kaggle e traz os datasets da Uber.</li>
                                    </ul>
                                    <div class="text-center mb-4">
                                        <video autoplay loop muted playsinline class="img-fluid rounded shadow">
                                            <source src="assets/camada_raw.mp4" type="video/mp4">
                                            Seu navegador não suporta vídeo HTML5.
                                        </video>
                                    </div>

                                    <!-- Camada BRONZE -->
                                    <h6 class="fw-bold mt-4 text-warning">Camada Bronze</h6>
                                    <p>
                                        Na camada Bronze ocorre a primeira transformação: selecionar apenas os arquivos CSV relevantes e convertê-los para o formato <strong>Parquet</strong>, 
                                        que é então enviado para o bucket Bronze.
                                    </p>
                                    <div class="text-center mb-4">
                                        <video autoplay loop muted playsinline class="img-fluid rounded shadow">
                                            <source src="assets/camada_bronze_op2.mp4" type="video/mp4">
                                            Seu navegador não suporta vídeo HTML5.
                                        </video>
                                    </div>

                                    <!-- Camada SILVER -->
                                    <h6 class="fw-bold mt-4 text-info">Camada Silver</h6>
                                    <p>
                                        A camada Silver concentra o <strong>tratamento e enriquecimento</strong> dos dados, dividida em duas etapas principais:
                                    </p>
                                    <ul>
                                        <li><code>transform_silver_uber_data.ipynb</code>: lê os dados em Parquet do bucket Bronze via PySpark, separa por tipo de transporte (Classes A a E) e gera um arquivo apenas com latitudes/longitudes únicas.</li>
                                        <li><code>geospatial_silver_data.ipynb</code>: lê esse arquivo de coordenadas, transforma-os em dados geoespaciais com GeoPandas, cruza com os shapefiles do Censo (Raw) e retorna um DataFrame PySpark.</li>
                                    </ul>
                                    <div class="text-center mb-4">
                                        <video autoplay loop muted playsinline class="img-fluid rounded shadow">
                                            <source src="assets/camada_silver_op2.mp4" type="video/mp4">
                                            Seu navegador não suporta vídeo HTML5.
                                        </video>
                                    </div>

                                    <!-- Camada GOLD -->
                                    <h6 class="fw-bold mt-4 text-warning">Camada Gold</h6>
                                    <p>
                                        Na camada Gold ocorre a <strong>unificação final</strong>.  
                                        Aqui, os dados das classes de transporte são combinados com as informações geoespaciais para identificar <em>onde</em> cada corrida ocorreu.
                                    </p>
                                    <p>
                                        Cada classe possui seu próprio notebook, o que facilita manutenção e análises específicas.  
                                        Ao final, os dados são carregados em um banco PostgreSQL, estruturando um <strong>Data Warehouse pronto para consumo</strong>.
                                    </p>
                                    <div class="text-center mb-4">
                                        <video autoplay loop muted playsinline class="img-fluid rounded shadow">
                                            <source src="assets/camada_gold.mp4" type="video/mp4">
                                            Seu navegador não suporta vídeo HTML5.
                                        </video>
                                    </div>


                                    <!-- Estrutura de diretórios -->
                                    <p class="mb-3">
                                        A estrutura do projeto também foi pensada para manter a organização dos notebooks em camadas bem definidas.  
                                        Cada etapa da pipeline (extração, tratamento, enriquecimento e carga) está separada em diretórios <code>raw</code>, <code>bronze</code>, <code>silver</code> e <code>gold</code>, 
                                        facilitando a manutenção, reprocessamento e entendimento do fluxo de dados.
                                    </p>

                                    <div class="text-center mb-4">
                                        <img class="img-fluid rounded shadow" src="assets/vscode_pipeline_structure.png" alt="Estrutura de pastas no VS Code">
                                    </div>


                                    <div class="d-flex align-items-center justify-content-between mb-4">
                                        <h5 class="text-primary fw-bolder mb-0">Aprendizados e Desafios</h5>
                                    </div>
                                    <!-- <h5 class="fw-bold mt-4">Aprendizados e Desafios</h5> -->
                                    <p>Trabalhar com dados geoespaciais foi um dos pontos mais interessantes do projeto. Além das transformações comuns, foi preciso lidar com cruzamentos espaciais e garantir precisão na localização de cada registro. Outro ponto importante foi estruturar a pipeline de forma modular, facilitando reprocessamentos e manutenção.</p>

                                    <p>Esse projeto também reforçou a importância de seguir boas práticas como versionamento, uso de camadas bem definidas e armazenamento eficiente dos dados intermediários.</p>
                                    <div class="d-flex align-items-center justify-content-between mb-4">
                                        <h5 class="text-primary fw-bolder mb-0">Conclusão</h5>
                                    </div>
                                    <!-- <h5 class="fw-bold mt-4">Conclusão</h5> -->
                                    <p>Esse projeto mostra bem o papel do engenheiro de dados em transformar dados brutos em algo realmente útil. Mais do que mover arquivos de um lado para o outro, a ideia foi construir uma solução que entrega valor, com dados organizados, enriquecidos e prontos para serem usados por times de BI, ciência de dados ou produtos.</p>

                                    <p><strong>O repositório com todo o código-fonte e documentação está disponível para consulta:</strong></p>

                                    <a href="https://github.com/alcidescoutinho95-bit/etl-kaggle-geoloc" target="_blank" class="btn btn-primary mt-3">Acessar Repositório no GitHub</a>
                                </div>
                            </div>
                        </div>
                    </div>
                </section>
            </div>
        </div>
    </div>
</main>

<!-- Footer -->
<footer class="bg-white py-4 mt-auto">
    <div class="container px-5">
        <div class="row align-items-center justify-content-between flex-column flex-sm-row">
            <div class="col-auto"><div class="small m-0">Copyright &copy; Alcides Gabriel 2025</div></div>
            <div class="col-auto">
                <a class="small" href="#!">Privacy</a>
                <span class="mx-1">&middot;</span>
                <a class="small" href="#!">Terms</a>
                <span class="mx-1">&middot;</span>
                <a class="small" href="contact.html">Contato</a>
            </div>
        </div>
    </div>
</footer>

<!-- Bootstrap JS -->
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js"></script>
<script src="js/scripts.js"></script>

</body>
</html>
